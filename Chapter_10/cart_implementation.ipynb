{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from typing import Optional\n",
    "from typing import SupportsFloat\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "outputs": [],
   "source": [
    "# is threshold smaller or equal to the feature of sample\n",
    "def split_func(sample: np.ndarray, feature_i: int, threshold: float) -> bool:\n",
    "    return sample[feature_i] >= threshold"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "outputs": [],
   "source": [
    "def divide_on_feature(x: np.ndarray, idx: int, val: float):\n",
    "    x_1 = np.array([sample for sample in x if split_func(sample, idx, val)])\n",
    "    x_2 = np.array([sample for sample in x if not split_func(sample, idx, val)])\n",
    "    return np.array([x_1, x_2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "outputs": [],
   "source": [
    "def log2(n: SupportsFloat) -> float:\n",
    "    return math.log(n) / math.log(2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "def calculate_entropy(y: np.ndarray) -> float:\n",
    "    unique_labels = np.unique(y)\n",
    "    entropy = 0.0\n",
    "    for label in unique_labels:\n",
    "        labelCount = len(y[y == label])\n",
    "        percentage = labelCount / len(y)\n",
    "        entropy += -percentage * log2(percentage)\n",
    "    return entropy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def calculate_info_gain(y: np.ndarray, y1: np.ndarray, y2: np.ndarray) -> float:\n",
    "    p1 = len(y1) / len(y)\n",
    "    p2 = len(y2) / len(y)\n",
    "    entropy = calculate_entropy(y)\n",
    "    info_gain = entropy - (p1 * calculate_entropy(y1) + p2 * calculate_entropy(y2))\n",
    "    return info_gain"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "def majority_vote(y: np.ndarray) -> float:\n",
    "    most_common = 0.0\n",
    "    max_count = 0\n",
    "    for label in np.unique(y):\n",
    "        count = len(y[y == label])\n",
    "        if count > max_count:\n",
    "            most_common = label\n",
    "    return most_common"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "class DecisionNode:\n",
    "    \"\"\"Class representing a node in a Decision Tree (Classification Tree).\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            feature_i: int = None,\n",
    "            threshold: float = None,\n",
    "            value: float = None,\n",
    "            true_branch: DecisionNode = None,\n",
    "            false_branch: DecisionNode = None,\n",
    "    ) -> None:\n",
    "        self.feature_i = feature_i\n",
    "        self.threshold = threshold\n",
    "        self.value = value\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "class ClassificationTree:\n",
    "    \"\"\"Class of Classification Tree\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self,\n",
    "            min_samples_split: int = 2,\n",
    "            min_impurity: float = 1e-7,\n",
    "            max_depth: float = np.inf\n",
    "    ) -> None:\n",
    "        self.root: DecisionNode = None\n",
    "        self.min_samples = min_samples_split\n",
    "        self.min_impurity = min_impurity\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "    def fit(self, x: np.ndarray, y: np.ndarray):\n",
    "        self.root = self._build_tree(x, y)\n",
    "\n",
    "    def _build_tree(self, x: np.ndarray, y: np.ndarray, current_depth: int = 0):\n",
    "        \"\"\"Recursive method that creates a subtree of DecisionNodes based on splitting the given input data according to the minimum impurity, the maximum depth and the minimum amount of samples.\"\"\"\n",
    "\n",
    "\n",
    "        largest_impurity = 0.0\n",
    "        best_criteria = {}\n",
    "        best_sets = {}\n",
    "\n",
    "        # add y (1D) as last column to x (2D)\n",
    "        full_x = np.concatenate((x, np.reshape(y, newshape=(-1, 1))), axis=1)\n",
    "        n_samples, n_features = full_x.shape\n",
    "\n",
    "        # only split the data if there are more than min_samples and the depth is not deeper than max_depth\n",
    "        if n_samples >= self.min_samples and current_depth <= self.max_depth:\n",
    "            # for each feature, check the impurity of the inputs at that distinct feature\n",
    "            for feature_i in range(n_features):\n",
    "                if feature_i < len(x):\n",
    "                    break\n",
    "                feature_values = x[:, feature_i]\n",
    "                unique_values = np.unique(feature_values) # no need to check impurity more than once per each distinct value\n",
    "\n",
    "                for val in unique_values:\n",
    "                    x_1, x_2 = divide_on_feature(full_x, feature_i, val)\n",
    "                    # length of x_1 and x_2 needs to be greater than 0\n",
    "                    if len(x_1) > 0 and len(x_2) > 0:\n",
    "                        y1 = x_1[:, n_features:]\n",
    "                        y2 = x_2[:, n_features:]\n",
    "                        x1 = x_1[:, :n_features]\n",
    "                        x2 = x_2[:, :n_features]\n",
    "\n",
    "                        impurity = calculate_info_gain(y, y1, y2)\n",
    "                        if impurity > largest_impurity:\n",
    "                            largest_impurity = impurity\n",
    "                            best_criteria = {\n",
    "                                \"feature_i\": feature_i,\n",
    "                                \"threshold\": val,\n",
    "                            }\n",
    "                            best_sets = {\n",
    "                                \"x_left\": x1,\n",
    "                                \"x_right\": x2,\n",
    "                                \"y_left\": y1,\n",
    "                                \"y_right\": y2\n",
    "                            }\n",
    "        # as long as the largest found impurity is greater than the min_impurity\n",
    "        if largest_impurity > self.min_impurity:\n",
    "            # build a subtree with the left half (smaller than threshold)\n",
    "            true_branch = self._build_tree(best_sets[\"x_left\"], best_sets[\"y_left\"], current_depth+1)\n",
    "            # build a subtree with the right values (greater than threshold)\n",
    "            false_branch = self._build_tree(best_sets[\"x_right\"], best_sets[\"y_right\"], current_depth+1)\n",
    "            return DecisionNode(\n",
    "                feature_i=best_criteria[\"feature_i\"],\n",
    "                threshold=best_criteria[\"threshold\"],\n",
    "                true_branch=true_branch,\n",
    "                false_branch=false_branch,\n",
    "            )\n",
    "\n",
    "        leaf_value = majority_vote(y)\n",
    "        return DecisionNode(value=leaf_value)\n",
    "\n",
    "    def predict_value(self, x: np.ndarray, tree: Optional[DecisionNode] = None):\n",
    "        if tree is None:\n",
    "            tree = self.root\n",
    "        # in case of leaf simply return the leaf value\n",
    "        if tree.value is not None:\n",
    "            return tree.value\n",
    "\n",
    "        # determine whether to check true_branch or false_branch\n",
    "        feature_value = x[tree.feature_i]\n",
    "        branch = tree.false_branch\n",
    "        if feature_value >= tree.threshold:\n",
    "            branch = tree.true_branch\n",
    "\n",
    "        return self.predict_value(x, branch)\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        y_pred = np.array([self.predict_value(xe) for xe in x])\n",
    "        return y_pred\n",
    "\n",
    "    def score(self, x: np.ndarray, y: np.ndarray):\n",
    "        y_pred = self.predict(x)\n",
    "        y_true = np.sum([y_pred_i == y_i for y_pred_i, y_i in zip(y_pred, y)])\n",
    "        length = len(y)\n",
    "\n",
    "        accuracy = y_true / length\n",
    "        return accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "dataset = load_wine()\n",
    "x = dataset.data\n",
    "y = dataset.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 24.07%\n"
     ]
    }
   ],
   "source": [
    "tree = ClassificationTree(min_samples_split=2, max_depth=6)\n",
    "tree.fit(x_train, y_train)\n",
    "\n",
    "accuracy = tree.score(x_test, y_test)\n",
    "print(f\"accuracy: {accuracy*100:.4}%\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}